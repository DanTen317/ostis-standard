\usepackage{scn}\begin{SCn}
    \scnsectionheader{Логико-семантическая модель ostis-системы автоматизации проектирования искусственных нейронных сетей, семантически совместимых с базами знаний ostis-систем}
    \begin{scnsubstruct}
        \scntext{введение}{
            Наличия \textit{Языка представления нейросетевых методов в базах знаний} и его интерпретатора позволяет обеспечить интерпретацию \textit{нейросетевого метода} в памяти \textit{ostis-системы}. Наличие в единой памяти не только экземпляров методов, но и понятий, их описывающих, создает основу для автоматизации процесса построения нейросетевых методов. В памяти \textit{ostis-системы} хранятся знания о том, методы какого класса могут решить задачу заданного класса, но экземпляров класса этого метода может не быть представлено в системе. На этот случай система должна иметь возможность сообщить пользователю о возможности решения, для которого, однако, необходимо погрузить в систему определенный метод. Так как система хранит в единой памяти задачу и требования к методу ее решения, появляется возможность спроектировать необходимый метод. Для этого необходимо наличие среды проектирования методов соответствующих классов. В случае \textit{нейросетевого метода}, речь идет об интеллектуальной среде построения \textit{нейросетевых методов}.\\
            В основе интеллектуальной среды построения \textit{нейросетевых методов} лежат соответствующие другу другу иерархии действий, задач и методов построения \textit{и.н.с.} Наличие такой иерархии позволит описать язык представления методов построения \textit{и.н.с.} и разработать интерпретатор этого языка.\\
            Построение иерархии соответствующих действий построения \textit{и.н.с.} следует начать с изучения этапов проектирования и обучения \textit{и.н.с.}, которые, в общем случае, выполняют все разработчики и.н.с.
        }

        \scnsegmentheader{Логико-семантическая модель ostis-системы автоматизации проектирования искусственных нейронных сетей, семантически совместимых с базами знаний ostis-систем}
        \begin{scnsubstruct}

            \scnheader{Предметная область интеллектуальной среды построения нейросетевых методов}
            \scnidtf{Предметная область фреймворка нейросетей}
            \scniselement{предметная область}
            \begin{scnhaselementrole}{максимальный класс объектов исследования}
            {интеллектуальная среда построения нейросетевых методов}
            \end{scnhaselementrole}
            \begin{scnhaselementrolelist}{класс объектов исследования}
                \scnitem{интеллектуальная среда построения нейросетевых методов}
                \scnitem{постановка задачи}
                \scnitem{предобработка выборки}
                \scnitem{разбиение выборки на обучающую, валидационную и тестовую (контрольную)}
                \scnitem{выбор класса нейросетевых методов в соответствии со сформулированной задачей}
                \scnitem{формирование спецификации на входные и выходные данные}
                \scnitem{выбор метода оптимизации}
                \scnitem{выбор минимизируемой функции ошибки}
                \scnitem{начальная инициализация параметров нейронной сети}
                \scnitem{выбора гиперпараметров и.н.с.}
                \scnitem{обучение модели на обучающей выборке}
                \scnitem{оценка эффективности и.н.с}
                \scnitem{действие трансляции условия задачи}
                \scnitem{действие классификации задачи}
                \scnitem{действие поиска подходящей обучающей выборки}
                \scnitem{действие формирования требований к обучающей выборке}
                \scnitem{методы оптимизации}
                \scnitem{минимизируемая функция ошибок}
                \scnitem{действие обучения и.н.с.}
                \scnitem{выборка}
                \scnitem{метод обучения и.н.с.}
                \scnitem{метод оптимизации}
                \scnitem{функция потерь}
            \end{scnhaselementrolelist}
            \begin{scnhaselementrolelist}{исследуемое отношение}
                \scnitem{обучающая выборка\scnrolesign}
                \scnitem{тестовая выборка\scnrolesign}
                \scnitem{валидационная выборка\scnrolesign}
                \scnitem{метод обучения\scnrolesign}
                \scnitem{функция потерь\scnrolesign}
            \end{scnhaselementrolelist}

            \scnheader{интеллектуальная среда построения нейросетевых методов}
            \begin{scnrelfromset}{этап построения нейросетевых методов}
                \begin{scnindent}
                    \scnitem{постановка задачи}
                    \scnitem{этап, связанный с выборкой}
                    \begin{scnindent}
                        \begin{scnrelfromset}{разбиение}
                            \scnitem{предобработка выборки}
                            \scnitem{разбиение выборки на обучающую, валидационную и тестовую (контрольную)}
                        \end{scnrelfromset}
                    \end{scnindent}
                    \scnitem{этап, связанные с импользуемыми моделями и.н.с}
                    \begin{scnindent}
                        \begin{scnrelfromset}{разбиение}
                            \scnitem{выбор класса нейросетевых методов в соответствии со сформулированной задачей}
                            \scnitem{формирование спецификации на входные и выходные данные}
                            \scnitem{выбор метода оптимизации}
                            \scnitem{выбор минимизируемой функции ошибки}
                            \scnitem{начальная инициализация параметров нейронной сети}
                            \scnitem{выбор гиперпараметров и.н.с.}
                            \scnitem{обучение модели на обучающей выборке}
                            \scnitem{оценка эффективности и.н.с}
                        \end{scnrelfromset}
                    \end{scnindent}
                \end{scnindent}
            \end{scnrelfromset}

            \scnheader{постановка задачи}
            \begin{scnrelfromset}{содержимое}
                \scnitem{входные данные}
                \begin{scnindent}
                    \scntext{пример}{изображения/видео, временные ряды, текст}
                \end{scnindent}
                \scnitem{выходные данные}
                \scnitem{требования к методу решения}
                \begin{scnindent}
                    \scntext{пример}{скорость, затраты по памяти и так далее}
                \end{scnindent}
                \scnitem{дополнительная информация}
                \begin{scnindent}
                    \scntext{пояснение}{информация, которая может помочь в построении метода решения задачи}
                \end{scnindent}
            \end{scnrelfromset}
            \begin{scnrelfromset}{декомпозиция}
                \scnitem{\textbf{действие трансляции условия задачи}}
                \scnitem{\textbf{действие классификации задачи}}
                \scnitem{\textbf{действие поиска подходящей обучающей выборки}}
                \scnitem{\textbf{действие формирования требований к обучающей выборке}}
            \end{scnrelfromset}


            \scnheader{действие трансляции условия задачи}
            \scniselement{действие}
            \scntext{пояснение}{Действие транслирует заданное с помощью \textit{интерфейса ostis-системы} (к примеру, естественно-языкового интерфейса) описание задачи в память ostis-системы. Действие необходимо в случае, когда условие задачи задается пользователем. Необходимо понимать, что описание задачи поступает в базу знаний не только от \textit{пользовательского интерфейса}. К примеру, задача может быть сформулирована самой системой в ходе ее жизнедеятельности.}
            \scntext{пояснение}{Данное действие является общим для всех ostis-систем, поэтому его рассмотрение выходит за рамки рассмотрения процесса построения интеллектуальной среды проектирования \textit{и.н.с.}}

            \scnheader{действие классификации задачи}
            \scniselement{действие}
            \scntext{пояснение}{Действие определяет класс задачи (задача регрессии, детекции, кластеризации и так далее), исходя из описания задачи в базе знаний.}

            \scnheader{действие поиска подходящей обучающей выборки}
            \scniselement{действие}
            \scntext{пояснение}{В базе знаний может храниться набор спецификаций выборок, к которым у ostis-системы есть доступ. Действие производит поиск выборок, которые могут быть использованы в качестве обучающей выборки.}

            \scnheader{действие формирования требований к обучающей выборке}
            \scniselement{действие}
            \scntext{пояснение}{Если обучающая выборка не была предоставлена и не была найдена, то необходимо сформировать описание требований к обучающей выборке, которое можно будет транслировать на язык пользовательского интерфейса и запросить необходимую выборку у пользователя.}

            \scnheader{предобработка выборки}
            \begin{scnrelfromset}{этап}
                \scnitem{очистка}
                \begin{scnindent}
                    \begin{scnrelfromset}{содержимое}
                        \scnitem{обнаружение признаков, которые имеют в общем случае некорректные значения}
                        \begin{scnindent}
                            \scntext{пример}{для каких-то образов значение признака может иметь неопределенное значение, либо значение, не совпадающее по типу, либо аномально большое или очень маленькое значение, которое встречается в редком числе случаев}
                        \end{scnindent}
                        \scnitem{методы устранения признаков, имеющие неопределённые значения}
                        \begin{scnindent}
                            \scntext{пояснение}{значения могут быть заменены средним значением этого признака, рассчитанным по всем образам (для непоследовательных данных), либо они могут быть заменены средним значением по соседним образам (в случае временных рядов), либо каким-то фиксированным значением}
                            \scntext{радикальное решение}{удаление образов, имеющих неопределенные значения признаков из выборки}
                            \begin{scnindent}
                                \scntext{примечание}{однако его лучше применять, если образов с отсутствующими значениями признаков немного. Для выбросов и аномалий применяются схожие стратегии (но только в том случае, если задача не состоит в прогнозировании этих аномалий)}
                            \end{scnindent}
                        \end{scnindent}
                    \end{scnrelfromset}
                    \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия очистки выборки}}, которое выполняется в случае обработки выборки, которая ранее не была представлена в памяти системы (к примеру, была получена от пользователя). Реализация интерпретатора (агента) данного действия требует описания в памяти классификации стратегий очистки данных и реализации методов применения этих стратегий}
                \end{scnindent}
                \scnitem{выявление содержательных признаков}
                \begin{scnindent}
                    \scntext{цель}{уменьшение размерности пространства признаков для снижения влияния эффекта переобучения на модель}
                    \begin{scnindent}
                        \scntext{реализация}{использование методов отбора признаков и выделения признаков}
                    \end{scnindent}

                    \scntext{задача}{инжиниринг признаков, состоящий в отборе признаков, влияющих на результат работы модели}
                    \begin{scnindent}
                        \scntext{примечание}{несодержательные признаки, которые никак не коррелируют с выходом модели, удаляются}
                        \begin{scnrelfromset}{содержимое}
                            \scnitem{формирование подмножества из исходных признаков (алгоритм последовательного обратного отбора, рекурсивный алгоритм обратного устранения признаков,  алгоритмы с использованием случайных лесов)}
                            \scnitem{извлечение информации для построения нового подпространства признаков (алгоритмы с использованием автоэнкодера)}
                        \end{scnrelfromset}
                    \end{scnindent}
                    \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия выявления содержательных признаков}}. Реализация интерпретатора (агента) данного действия требует описания в памяти классификации стратегий уменьшения размерности признакового пространства и реализации методов применения этих стратегий}
                \end{scnindent}
                \scnitem{трансформация}
                \begin{scnindent}
                    \scntext{задача}{подготовка данных к обучению}
                    \begin{scnindent}
                        \scntext{примечание}{следует уделить особое внимание наличию категориальных признаков, чаще всего заданных строковыми типами}
                        \begin{scnrelfromset}{содержимое}
                            \scnitem{категориальные признаки}
                            \begin{scnindent}
                                \begin{scnrelfromset}{разбиение}
                                    \scnitem{номинальные признаки}
                                    \begin{scnindent}
                                        \scntext{способ кодирования}{последовательное числовое кодирование}
                                        \begin{scnindent}
                                            \scntext{пример}{1,2,3,...}
                                        \end{scnindent}
                                    \end{scnindent}
                                    \scnitem{порядковые признаки}
                                    \begin{scnindent}
                                        \scntext{свойство}{равноправие}
                                        \begin{scnindent}
                                            \scntext{пояснение}{порядковые признаки не могут сравниваться по числовому коду}
                                            \begin{scnindent}
                                                \scntext{пример}{пол - 0/1}
                                            \end{scnindent}
                                        \end{scnindent}
                                        \scntext{способ кодирования}{прямое кодирование}
                                        \begin{scnindent}
                                            \scntext{пояснение}{создание и использование фиктивных признаков по количеству значений исходного}
                                            \scntext{пример}{признак пол(мужской, женский) преобразуется в два новых признака мужской и женский с соответствующими значениями для имеющихся образов}
                                        \end{scnindent}
                                    \end{scnindent}
                                \end{scnrelfromset}
                                \scntext{действие преобразования}{масштабирование}
                                \begin{scnindent}
                                    \scntext{описание}{приведение значений признаков к одному общему интервалу}
                                    \begin{scnindent}
                                        \scntext{пояснение}{это особенно актуально для признаков, имеющих несоразмерные выборочные средние значения по всем образам}
                                        \scntext{пример}{один признак в среднем имеет значение 10000 и 12}
                                        \scntext{примечание}{это может проявится в выполнении минимизации только по признаку с наибольшими значениями и плохой сходимости метода обучения}
                                    \end{scnindent}
                                    \begin{scnrelfromset}{способ реализации}
                                        \scnitem{нормализация на отрезок (min-max нормализация)}
                                        \begin{scnindent}
                                            \scntext{примечание}{чаще всего используется}
                                            \scnrelfrom{формула}{
                                                \begin{equation*}
                                                    x^i_{norm}=\frac{x^i-x_{min}}{x_{max}-x_{min}}
                                                \end{equation*}
                                                где \textit{$x^i$} --- значение признака для отдельно взятого образа i, \texit{$x_{min}$} --- наименьшее значение для признака, \textit{$x_{max}$} --- наибольшее значение для признака
                                            }
                                        \end{scnindent}
                                        \scnitem{применение стандартизации признаков}
                                        \begin{scnindent}
                                            \scnrelfrom{формула}{
                                                \begin{equation*}
                                                    x^i_{std}=\frac{x^i-\mu(x)}{\sigma(x)}
                                                \end{equation*}
                                                где \textit{$\mu(x)$} --- выборочное среднее отдельного признака, \texit{$\sigma(x)$} --- стандартное отклонение
                                            }
                                            \scntext{примечание}{стандартизация сохраняет полезную информацию о выбросах в исходных данных и делает алгоритм обучения менее чувствительным к ним}
                                        \end{scnindent}
                                        \scnitem{применение дискретизации}
                                        \begin{scnindent}
                                            \scntext{пояснение}{применяется для перехода от вещественного признака к порядковому за счет кодирования интервалов одним значением}
                                            \scntext{пример}{если признак отражает возраст человека, то может быть произведена дискретизация значений с выделением определенных возрастных групп, где каждая группа будет кодироваться одним целым числом}
                                        \end{scnindent}

                                    \end{scnrelfromset}
                                \end{scnindent}
                            \end{scnindent}
                        \end{scnrelfromset}
                    \end{scnindent}
                    \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия трансформации выборки}}. Реализация интерпретатора (агента) данного действия требует описания в памяти классификации методов масштабирования признаков и реализации методов применения этих стратегий}
                \end{scnindent}
            \end{scnrelfromset}

            \scnheader{разбиение выборки на обучающую, валидационную и тестовую (контрольную)}
            \scntext{пояснение}{производится разбиение всей выборки данных, на обучающую, тестовую и, в некоторых случаях, валидационную}
            \scntext{примечание}{валидационная выборка используется для оценки влияния изменения гиперпараметров на результат обучения и может применяться как дополнительный инструмент для этого наравне с сеточным поиском}
            \scntext{описание}{разбиение проводится в соотношении 3:1:1, в процентах (60/20/20), если валидационная выборка не используется, то 80/20}
            \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия разбиения выборки}}}

            \scnheader{выбор класса нейросетевых методов в соответствии со сформулированной задаей}
            \scntext{задача}{выбор основной архитектуры и.н.с, которая будет использоваться при обучении}
            \begin{scnindent}
                \scntext{примечание}{выбор относительно условный, то есть исследователь не ограничен исползованием только одного типа и.н.с. для решения задачи(как например, свёрточной сети для изображений, поскольку изображения можно обрабатывать и обычным многослойным персептроном). Речь идёт скорее о рекомендованной архитектуре, но это не  исключает использование любых других выриантов архитектур и их сочетаний в рамках одной модели}
                \begin{scnindent}
                    \begin{scnrelfromset}{пример рекомендации}
                        \begin{scnindent}
                            \scnitem{изображения/видео --- сверхточные нейронные сети}
                            \scnitem{временные ряды --- многослойные персептроны или рекуррентные сети}
                            \scnitem{текстовая информация --- многослойные персептроны или рекуррентные сети}
                            \scnitem{наборы характеристик некоторых объектов (например, спецификации автомобилей) --- многослойный персептрон}
                        \end{scnindent}
                    \end{scnrelfromset}
                \end{scnindent}
            \end{scnindent}

            \scnheader{формирование спецификации на входные и выходные дqанные}
            \scntext{задача}{выполнение дополнительных преобразований данных, связанных с изменением структур хранения}
            \begin{scnindent}
                \scntext{пример}{преобразование многомерного массива в одномерный, конвертация типов}
            \end{scnindent}
            \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия формирования спецификации входов и выходов и.н.с.}}}

            \scnheader{выбор метода оптимизации}
            \scntext{задача}{выбрать \textbf{\textit{метод оптимизации}}}
            \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия выбора метода оптимизации}}}

            \scnheader{методы оптимизации}
            \begin{scnrelfromset}{разбиение}
                \scnitem{стохастический градиентный спуск}
                \begin{scnindent}
                    \scnidtf{stochastic gradient descent}
                    \scnidtf{SGD}
                \end{scnindent}
                \scnitem{метод Нестерова}
                \scnitem{адаптивный градиент}
                \begin{scnindent}
                    \scnidtf{adaptive gradient}
                    \scnidtf{AdaGrad}
                \end{scnindent}
                \scnitem{адаптивная оценка момента}
                \begin{scnindent}
                    \scnidtf{adaptive moment estimation}
                    \scnidtf{Adam}
                \end{scnindent}
                \scnitem{среднеквадратическое распространение}
                \begin{scnindent}
                    \scnidtf{root mean square propagation}
                    \scnidtf{RMSProp}
                \end{scnindent}
            \end{scnrelfromset}

            \scnheader{выбор минимизируемой функции ошибок}
            \scntext{задача}{определение функции ошибок, которая будет минимизироваться}
            \begin{scnindent}
                \scntext{пример}{MSE лучше подходит для задач регрессии и для кластеризации, CE --- для классификационных задач}
            \end{scnindent}
            \scntext{примечание}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия выбора минимизируемой функции ошибки}}}

            \scnheader{минимизируемая функция ошибок}
            \begin{scnrelfromset}{разбиение}
                \scnitem{MSE}
                    \begin{scnindent}
                        \scntext{формула}{
                            \begin{equation*}
                                MSE = \frac{1}{n} \sum_{i=1}^n (Y_i - \widetilde{Y_i})^2
                            \end{equation*}
                            где \textit{n} --- размер обучающей выборки, $Y_i$ --- эталонное значение функции, $\widetilde{Y_i}$ --- результат, полученный НС
                        }
                    \end{scnindent}
                \scnitem{CE}
                \begin{scnindent}
                    \begin{scnrelfromset}{декомпозиция}
                        \scnitem{CE случай 2-классовой классификации}
                        \begin{scnindent}
                            \scntext{формула}{
                                \begin{equation*}
                                    CE = - \frac{1}{n} \sum_{i=1}^n (Y_i\log(\widetilde{Y_i}) + (1-Y_i)\log(1 - \widetilde{Y_i}))
                                \end{equation*}
                            }
                        \end{scnindent}
                        \scnitem{CE случай многоклассовой классификации}
                        \begin{scnindent}
                            \scntext{формула}{
                                \begin{equation*}
                                    CE = - \frac{1}{n} \sum_{i=1}^n \sum_{c=1}^M Y_i^c \log{\widetilde{Y}_i^c}
                                \end{equation*}
                            }
                        \end{scnindent}
                    \end{scnrelfromset}
                \end{scnindent}
            \end{scnrelfromset}

            \scnheader{начальная инициализация параметров нейронной сети}
            \scntext{цель}{инициализация весовых коэффициентов и порогов нейронной сети}
            \begin{scnrelfromset}{способ}
                \scnitem{инициализация значениями из равномерного распределения на каком-то небольшом интервале}
                \begin{scnindent}
                    \scntext{пример}{[-0.1, 0.1]}
                \end{scnindent}
                \scnitem{инициализация значениями из стандартного нормального распределения}
                \scnitem{инициализация по методу Ксавье}
                \begin{scnindent}
                    \scntext{пояснение}{Применяется для предотвращения резкого уменьшения или увеличения значений выхода нейронных элементов после применения функции активации при прямом прохождении образа через глубокую нейронную сеть. Фактически инициализация этим методом осуществляется посредством выбора значений из равномерного распределения на отрезке $[- \sqrt{6} / \sqrt{n_i+n_{i+1}}, \sqrt{6} / \sqrt{n_i+n_{i+1}}]$, где $n_i$ --- это число входящих связей в данный слой, а $n_i$ --- число исходящих связей из данного слоя. Таким образом, инициализация этим методом проводится для разных слоев нейронной сети из разных отрезков}
                \end{scnindent}
                \scnitem{инициализация, полученная из предобученной модели}
                \begin{scnindent}
                    \scntext{пояснение}{Вариант инициализации, который предполагает использование в качестве \scnqq{стартовой} модели предобученной модели, взятой из некоторого репозитория предобученных моделей, обученную самим исследователем или в процессе работы интеллектуальной системы.}
                \end{scnindent}
                \scnitem{инициализация по методу Кайминга}
                \begin{scnindent}
                    \scntext{пояснение}{Данный метод инициализации применяется для решения проблемы \scnqq{затухающего} градиента и \scnqq{взрывающегося} градиента. Производится посредством выбора значений из равномерного распределения на отрезке $[-\sqrt{2} / \sqrt{(1+a^2)fan}, \sqrt{2} / \sqrt{(1+a^2)fan}]$, где \textit{a} --- угол наклона к оси абсцисс для отрицательной части области определения функции активации типа ReLU (для обычной ReLU функции этот параметр равен 0), $fan$ --- параметр режима работы, который для фазы прямого распространения равен количеству входящих связей (для устранения эффекта \scnqq{взрывающегося} градиента), а для фазы обратного распространения --- количеству выходящих (для устранения эффекта \scnqq{затухающего} градиента).}
                \end{scnindent}
            \end{scnrelfromset}
            \scntext{примечание}{В интеллектуальной среде проектирования данный этап соответствует выполнению действия начальной инициализации и.н.с..}

            \scnheader{выбор гиперпараметров и.н.с.}
            \scntext{пояснение}{На практике некоторые гиперпараметры (такие как количество слоев, их типы, количество нейронов в слое) часто определяются экспериментально, в процессе итеративного поиска лучшего варианта решения задачи. Хотя способы частично автоматизировать этот процесс существуют, они все же рассчитаны на наличие некоторых предусловий проведения эксперимента, в частности интервалов изменения параметра (например, скорости обучения).}
            \begin{scnrelfromset}{выбор}
                \scnitem{гиперпараметр}
                \begin{scnindent}
                    \begin{scnrelfromset}{декомпозиция}
                        \scnitem{параметры обучения и.н.с.}
                        \scnitem{архитектура модели и.н.с.}
                    \end{scnrelfromset}
                \end{scnindent}
            \end{scnrelfromset}
            \scntext{цель}{Нахождение оптимальных гиперпараметров}
            \begin{scnindent}
                \scntext{пример}{использование метода сеточного поиска, который позволяет проверить значения гиперпараметров, взятые с определенным шагом или из определенного интервала (кортежа). С помощью этого метода выбирается оптимальный набор гиперпараметров, который дает лучшие результаты, он используется для последующего дообучения. Или же, если полученные результаты являются приемлемыми, то процесс дальнейшего обучения вообще не проводится. Следует отметить затратность данного метода, так как фактически осуществляется перебор различных значений параметров обучения. Для снижения объема работы применяется метод случайного поиска.}
            \end{scnindent}
            \scntext{пояснение}{Для оптимизации архитектуры определяются типы слоев нейронной сети, количество нейронных элементов в каждом слое, их характеристики --- функция активации, для сверточных элементов --- размер ядра, а также параметры padding и шаг свертки (stride).}
            \scntext{примечаниея}{Здесь же может осуществляться оценка не только пользовательского варианта сети, но и предобученной архитектуры. Основное правило при выборе --- количество параметров модели не должно превышать размер обучающей выборки. Для предобученных архитектур это ограничение снимается.}
            \scntext{примечание}{В интеллектуальной среде проектирования данный этап соответствует выполнению действия выбора гипперпараметров и.н.с.. Действие использует классификацию и спецификации гиперпараметров и.н.с.}

            \header{обучение модели на обучающей выборке}
            \scntext{задача}{обучение модели до достижения выбранной точности (оценивается на тестовой выборке) или по другим заданным критериям (достижение заданного количества эпох обучения, неизменность точности на протяжении заданного количества эпох, падение точности на валидационной выборке и так далее)}
            \scntext{примчение}{в интеллектуальной среде проектирования данный этап соответствует выполнению \textbf{\textit{действия обучения и.н.с.}}. Действие обучения \textit{и.н.с.} --- действие, в ходе которого реализуется определенный метод обучения \textit{и.н.с.} с заданными параметрами обучения \textit{и.н.с.}, методом оптимизации и функцией потерь}

            \scnheader{действие обучения и.н.с.}
            \scnidtf{действие обучения искусственной нейронной сети}
            \scnsubset{действие конфигурации весовых коэффициентов и.н.с.}
            \scndefinition{\textbf{\textit{действие обучения и.н.с.}} --- действие, в ходе которого реализуется определенный метод обучения и.н.с. с заданными параметрами обучения и.н.с, методом оптимизации и функцией потерь.}
            \begin{scnrelfromset}{известные проблемы}
                \scnfileitem{Переобучение --- проблема, возникающая при обучении и.н.с., заключающаяся в том, что сеть хорошо адаптируется к п.в.а. из обучающей выборки, при этом теряя способность к обобщению. Переобучение возникает из-за применения неоправданно сложной модели при обучении и.н.с. Это происходит, когда количество настраиваемых параметров и.н.с. намного больше размера обучающей выборки. Возможные варианты решения проблемы заключаются в упрощении модели, увеличении выборки, использовании регуляризации (параметр регуляризации, техника dropout и т.д.).\\
                Обнаружение переобученности сложнее, чем недообученности. Как правило, для этого применяется кросс-валидация на валидационной выборке, позволяющая оценить момент завершения процесса обучения. Идеальным вариантом является достижение баланса между переобученностью и недообученностью.}
                \scnfileitem{Недообучение --- проблема, возникающая при обучении и.н.с., заключающаяся в том, что сеть дает одинаково плохие результаты на обучающей и контрольной выборках. Чаще всего такого рода проблема возникает при недостаточном времени, затраченном на обучение модели. Однако это может быть вызвано и слишком простой архитектурой модели либо малым размером обучающей выборки. Соответственно решение, которое может быть принято ML-инженером, заключается в устранении этих недостатков: увеличение времени обучения, использование модели с большим числом настраиваемых параметров, увеличение размера обучающей выборки, а также уменьшение регуляризации и более тщательный отбор признаков для обучающих примеров.}
            \end{scnrelfromset}
            \scnrelfrom{описание примера}{\scnfileimage{Contents/part_ps/src/images/sd_ps/sd_ann/ann_trainning_scg.png}}

            \scnheader{выборка}
            \scnsubset{множество}
            \scntext{пояснение}{\textbf{\textit{выборка}} --- множество п.в.а., используемых в процессе обучения, тестирования и архитектурной настройки и.н.с.}

            \scnheader{обучающая выборка\scnrolesign}
            \scnidtf{training set\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{действие обучения и.н.с.}
            \scnrelfrom{второй домен}{выборка}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{действие обучения и.н.с.}
                    \scnitem{выборка}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{обучающая выборка\scnrolesign}} --- ролевое отношение, связывающее действие обучения и.н.с. с выборкой, используемой для изменения настраиваемых параметров и.н.с. в процессе ее обучения.}

            \scnheader{тестовая выборка\scnrolesign}
            \scnidtf{test set\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{действие обучения и.н.с.}
            \scnrelfrom{второй домен}{выборка}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{действие обучения и.н.с.}
                    \scnitem{выборка}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{тестовая выборка\scnrolesign}} --- ролевое отношение, связывающее действие обучения и.н.с. с выборкой, используемой для проверки обобщающей способности обученной и.н.с.}
            \scntext{примечание}{Элементы контрольной выборки не используются в процессе обучения.}

            \scnheader{валидационная выборка\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{действие обучения и.н.с.}
            \scnrelfrom{второй домен}{выборка}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{действие обучения и.н.с.}
                    \scnitem{выборка}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{валидационная выборка\scnrolesign}} --- ролевое отношение, связывающее действие обучения и.н.с. с выборкой, используемой для определения (настройки) архитектурных параметров и.н.с. и параметров обучения.}
            \scntext{примечание}{Элементы валидационной выборки не используются в процессе обучения (не входят в обучающую выборку).}

            \scnheader{метод обучения и.н.с.}
            \scnsubset{метод}
            \scntext{пояснение}{\textbf{\textit{метод обучения и.н.с.}} --- метод итеративного поиска оптимальных значений настраиваемых параметров и.н.с., минимизирующих некоторую заданную функцию потерь.}
            \scntext{примечание}{Стоит отметить, что хотя целью применения метода обучения является минимизация функции потерь, \scnqqi{полезность} полученной после обучения модели можно оценить только по достигнутому уровню ее обобщающей способности. }
            \scnsuperset{метод обучения с учителем}
            \begin{scnindent}
                \scntext{пояснение}{\textbf{\textit{метод обучения с учителем}} --- метод обучения с использованием заданных целевых переменных. }
                \scnsuperset{метод обратного распространения ошибки}
                \begin{scnindent}
                    \scnidtf{м.о.р.о.}
                    \scntext{алгоритм}{\\
                        \begin{minipage}{\linewidth}
                            \begin{algorithm}[H]
                                \KwData{$X$ --- данные, $E_t$ --- желаемый отклик (метки), $E_m$ --- желаемая ошибка (в соответствии с выбранной функцией потерь)}
                                \KwResult{обученная нейронная сеть \textit{Net}}
                                инициализация весов \textit{W} и порогов \textit{T};\\
                                \Repeat{$E<E_m$}{
                                    \ForEach{$x \in X$ $\And$ $e \in E_t$}{
                                        фаза прямого распространения сигнала: вычисляются активации для всех слоев и.н.с.;\\
                                        фаза обратного распространения ошибки: вычисляются ошибки для последнего слоя и всех предшествующих слоев;\\
                                        изменение настраиваемых параметров и.н.с. в соответствии с вычисленными ошибками;\\
                                    }
                                    вычисление общей ошибки E на данной эпохе;
                                }
                            \end{algorithm}
                        \end{minipage}
                    }
                    \scntext{примечание}{м.о.р.о. использует заданный метод оптимизации и заданную функцию потерь для реализации фазы обратного распространения ошибки и изменения настраиваемых параметров и.н.с. Одним из самых распространенных методов оптимизации является метод стохастического градиентного спуска. Приведенный м.о.р.о. используется для реализации последовательного варианта обучения.}
                    \scntext{примечание}{Следует также отметить, что несмотря на то, что метод отнесен к методам обучения с учителем, в случае использования м.о.р.о. для обучения автокодировщиков в классических публикациях он рассматривается как метод обучения без учителя, поскольку в данном случае размеченные данные отсутствуют.}
                \end{scnindent}
            \end{scnindent}
            \scnsuperset{метод обучения без учителя}
            \begin{scnindent}
                \scntext{пояснение}{\textbf{\textit{метод обучения без учителя}} --- метод обучения без использования заданных целевых переменных (в режиме самоорганизации)}
                \scntext{пояснение}{В ходе выполнения алгоритма метода обучения без учителя выявляются полезные структурные свойства набора. Неформально его понимают как метод для извлечения информации из распределения, выборка для которого не была вручную аннотирована человеком (\scncite{Goodfellow2017}). }
            \end{scnindent}

            \scnheader{метод обучения\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{действие обучения и.н.с.}
            \scnrelfrom{второй домен}{метод обучения и.н.с.}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{действие обучения и.н.с.}
                    \scnitem{метод обучения и.н.с.}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{метод обучения\scnrolesign}} --- ролевое отношение, связывающее действие обучения и.н.с. с методом обучения,  использующимся для обучения и.н.с. в рамках этого действия.}

            \scnheader{метод оптимизации}
            \scnsubset{метод}
            \scndefinition{\textbf{\textit{метод оптимизации}} --- метод для минимизации целевой функции потерь при обучении и.н.с.}
            \begin{scnrelfromlist}{включение}
                \scnitem{SGD}
                \begin{scnindent}
                    \scnidtf{стохастический градиентный спуск}
                    \scnidtf{с.г.с.}
                    \scnidtf{stochastic gradient descent}
                    \scntext{примечание}{В методе стохастического градиентного спуска корректировка настраиваемых параметров и.н.с. выполняется в направлении максимального уменьшения функции стоимости, т.е. в направлении, противоположном вектору градиента функции потерь (\scncite{Haykin2006})}
                \end{scnindent}
                \scnitem{Nesterov method}
                \begin{scnindent}
                    \scnidtf{метод Нестерова}
                    \scntext{примечание}{Обучение методом с.г.с. иногда происходит очень медленно. Импульсный метод позволяет ускорить обучение, особенно в условиях высокой кривизны, небольших, но устойчивых градиентов или зашумленных градиентов. В импульсном методе вычисляется экспоненциально затухающее скользящее среднее прошлых градиентов и продолжается движение в этом направлении. Метод Нестерова является вариантом импульсного алгоритма, в котором градиент вычисляется после применения текущей скорости (\scncite{Goodfellow2017})}
                \end{scnindent}
                \scnitem{AdaGrad}
                \begin{scnindent}
                    \scnidtf{adaptive gradient}
                    \scntext{примечание}{Данный метод по отдельности адаптирует скорости обучения всех настраиваемых параметров и.н.с., умножая их на коэффициент, обратно пропорциональный квадратному корню из суммы всех прошлых значений квадрата градиента (\scncite{Duchi2011})}
                \end{scnindent}
                \scnitem{RMSProp}
                \begin{scnindent}
                    \scnidtf{root mean square propagation}
                    \scntext{примечание}{Данный метод является модификацией AdaGrad, которая позволяет улучшить его поведение в невыпуклом случае путем изменения способа агрегирования градиента на экспоненциально взвешенное скользящее среднее. Использование экспоненциально взвешенного скользящего среднего гарантирует повышение скорости сходимости после обнаружения выпуклой впадины, как если бы внутри этой впадины алгоритм AdaGrad был инициализирован заново (\scncite{Goodfellow2017})}
                \end{scnindent}
                \scnitem{Adam}
                \begin{scnindent}
                    \scnidtf{adaptive moments}
                    \scntext{примечание}{Данный метод можно рассматривать как комбинацию RMSProp и AdaGrad    (\scncite{Kingma2014}). Помимо усредненного первого момента, данный метод использует усредненное значение вторых моментов градиентов}
                \end{scnindent}
            \end{scnrelfromlist}
            \scntext{примечание}{Успешность применения методов оптимизации зависит главным образом от знакомства пользователя с соответствующим алгоритмом (\scncite{Goodfellow2017}). }


            \scnheader{метод оптимизации\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{метод обучения и.н.с.}
            \scnrelfrom{второй домен}{метод оптимизации}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{метод обучения и.н.с.}
                    \scnitem{метод оптимизации}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{метод оптимизации\scnrolesign}} --- ролевое отношение, связывающее метод обучения и.н.с. с методом оптимизации, использующимся для обучения и.н.с. с помощью данного метода.}

            \scnheader{функция потерь}
            \scnsubset{функция}
            \scntext{пояснение}{\textbf{\textit{функция потерь}} --- функция, используемая для вычисления ошибки, рассчитываемой как разница между фактическим эталонным значением и прогнозируемым значением, получаемым и.н.с.}
            \begin{scnrelfromlist}{включение}
                \scnitem{MSE}
                \begin{scnindent}
                    \scnidtf{mean square error}
                    \scnidtf{средняя квадратичная ошибка}
                    \scntext{формула}{
                        \begin{equation*}
                            MSE = \frac{1}{L} \sum_{l=1}^L \sum_{i=1}^m (y_i^l - e_i^l)^2
                        \end{equation*}
                        где $y_i^l$ --- прогноз модели, $e_i^l$ --- ожидаемый (эталонный) результат, \textit{m} --- размерность выходного вектора, \textit{L} --- объем обучающей выборки.}
                \end{scnindent}
                \scnitem{BCE}
                \begin{scnindent}
                    \scnidtf{binary cross entropy}
                    \scnidtf{бинарная кросс-энтропия}
                    \scntext{формула}{
                        \begin{equation*}
                            BCE = - \sum_{l=1}^L (e^l \log(y^l) + (1 - e^l)\log(1 - y^l))
                        \end{equation*}
                        где $y^l$ --- прогноз модели, $e^l$ --- ожидаемый (эталонный) результат: \textit{0} или \textit{1}, \textit{L} --- объем обучающей выборки.}
                    \scntext{примечание}{для бинарной кросс-энтропии в выходном слое и.н.с. будет находиться один нейрон}
                \end{scnindent}
                \scnitem{MCE}
                \begin{scnindent}
                    \scnidtf{multi-class cross entropy}
                    \scnidtf{мультиклассовая кросс-энтропия}
                    \scntext{формула}{
                        \begin{equation*}
                            MCE = - \sum_{l=1}^L \sum_{i=1}^m e_{~i}^l \log(y_{~i}^l)
                        \end{equation*}
                        где $y_{~i}^l$ --- прогноз модели, $e_i^l$ --- ожидаемый (эталонный результат), \textit{m} --- размерность выходного вектора.}
                    \scntext{примечание}{для мультиклассовой кросс-энтропии количество нейронов в выходном слое и.н.с. совпадает с количеством классов}
                \end{scnindent}
            \end{scnrelfromlist}
            \scntext{примечание}{Для решения задачи классификации рекомендуется использовать бинарную или мультиклассовую кросс-энтропийную функцию потерь, для решения задачи регрессии рекомендуется использовать среднюю квадратичную ошибку.}

            \scnheader{функция потерь\scnrolesign}
            \scniselement{ролевое отношение}
            \scnrelfrom{первый домен}{метод обучения и.н.с.}
            \scnrelfrom{второй домен}{функция потерь}
            \scnrelfrom{область определения}{\scnnonamednode}
            \begin{scnindent}
                \begin{scnreltoset}{объединение}
                    \scnitem{метод обучения и.н.с.}
                    \scnitem{функция потерь}
                \end{scnreltoset}
            \end{scnindent}
            \scntext{пояснение}{\textbf{\textit{функция потерь\scnrolesign}} --- ролевое отношение, связывающее метод обучения и.н.с. с функцией потерь, использующимся для обучения и.н.с. с помощью данного метода.}

            \scnheader{оценка эффективности и.н.с}
            \scntext{пояснение}{После выполнения обучения осуществляется оценка полученной модели с помощью метрик оценки качества.}
            \begin{scnrelfromset}{визуализация}
                \scnitem{матрица ошибок}
                \scnitem{ROC-кривая}
            \end{scnrelfromset}

            \scnheader{матрица ошибок}
            \scnsubset{матрица}
            \begin{scnrelfromset}{содержимое}
                \scnitem{число истинно-положительных предсказаний}
                \scnitem{число истинно-отрицательных предсказаний}
                \scnitem{число ложно-положительных предсказаний}
                \scnitem{число ложно-отрицательных предсказаний}
            \end{scnrelfromset}
            \scnrelfrom{схема}{\scnitem{\scnfileimage[20em]{Contents/part_methods_tools/src/images/autom_design_neural_network_logical_model/confusion_matrix.png}}}

            \scnheader{ROC-кривая}
            \scnsubset{график}
            \scnidtf{receiver operating characteristic}
            \scntext{пояснение}{\textbf{\textit{ROC-кривая}} --- это график, в котором, основываясь на заданном пороге решения классификатора, рассчитываются доли ложноположительных и истинно положительных исходов.}
            \scntext{примечание}{Основываясь на ROC-кривой, высчитывается AUC-показатель (площадь под кривой), которая используется в качестве характеристики качества модели.}
            \scntext{примечание}{В интеллектуальной среде проектирования данный этап соответствует выполнению действия оценки эффективности и.н.с..}

            \bigskip
        \end{scnsubstruct}

        \scnendsegmentcomment{Операционная семантика sc-моделей искусственных нейронных сетей, используемых в ostis-системах}

        \bigskip
    \end{scnsubstruct}

    \scnendcurrentsectioncomment


\end{SCn}